{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25860737-2a22-4dd3-8f9c-1f8039f1a67f",
   "metadata": {},
   "source": [
    "# Prompt\n",
    "\n",
    "You have graduated from this class, and are a huge success!\n",
    "You landed a job doing data science at some fancy company.\n",
    "\n",
    "You just got a new client with some really interesting problems you get to solve.\n",
    "Unfortunately, because of a big mess-up on their side the data's metadata got corrupted\n",
    "(and the person that used to maintain the data just took a vow of silence and moved to a bog).\n",
    "\n",
    "The only column you are sure about is the `label` column,\n",
    "which contains a numeric label for each row.\n",
    "Aside from that, the client does not know anything about the names, content, or even data types for each column.\n",
    "\n",
    "Your task is to explore, clean, and analyze this data.\n",
    "You should have already received an email with the details on obtaining your unique data.\n",
    "Place it in the same directory as this notebook (and your `local_grader.py` script) and name it `data.txt`.\n",
    "\n",
    "*I know this prompt may sound unrealistic, but I have literally been in a situation exactly like this.\n",
    "I was working at a database startup, and one of our clients gave us data with over 70 columns and more than a million records and told us:\n",
    "\"The person who used to manage the data is no longer working with us, but this was the data they used to make all their decisions.\n",
    "We also lost all the metadata information, like column names.\"\n",
    "...\n",
    "Working in industry is not always glamorous.\n",
    "-Eriq*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb229b6-7448-4d18-8d66-ae09853ed1cd",
   "metadata": {},
   "source": [
    "# Part 0: Explore Your Data\n",
    "\n",
    "Before you start doing things to/with your data, it's always a good idea to load up your data and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb1e1f63-a84d-4452-b52b-1aacaee00148",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Modify this to point to your data.\n",
    "unique_data = pandas.read_csv('data.txt', sep = \"\\t\")\n",
    "unique_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7320acb5-49a8-4a94-a044-36bc5056e87c",
   "metadata": {},
   "source": [
    "Don't forget to checkout the column information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97970b3-3439-44f8-a586-12e2b7e66a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 972 entries, 0 to 971\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   label   972 non-null    int64  \n",
      " 1   col_00  968 non-null    object \n",
      " 2   col_01  969 non-null    object \n",
      " 3   col_02  958 non-null    object \n",
      " 4   col_03  966 non-null    object \n",
      " 5   col_04  961 non-null    float64\n",
      " 6   col_05  963 non-null    object \n",
      " 7   col_06  963 non-null    float64\n",
      " 8   col_07  965 non-null    object \n",
      " 9   col_08  965 non-null    object \n",
      " 10  col_09  964 non-null    object \n",
      " 11  col_10  965 non-null    object \n",
      " 12  col_11  962 non-null    object \n",
      "dtypes: float64(2), int64(1), object(10)\n",
      "memory usage: 98.8+ KB\n"
     ]
    }
   ],
   "source": [
    "unique_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4522967-f408-4b57-9f8b-1a7df188ec4f",
   "metadata": {},
   "source": [
    "And any numeric information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b927511d-c9a3-44a1-8cf5-e6257396a92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>col_04</th>\n",
       "      <th>col_06</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>972.000000</td>\n",
       "      <td>961.000000</td>\n",
       "      <td>963.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.541152</td>\n",
       "      <td>0.533717</td>\n",
       "      <td>0.540244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.703983</td>\n",
       "      <td>0.742583</td>\n",
       "      <td>0.936276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.715600</td>\n",
       "      <td>-3.107300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>-0.072050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.511800</td>\n",
       "      <td>0.550600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.040300</td>\n",
       "      <td>1.151550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.034800</td>\n",
       "      <td>3.898900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label      col_04      col_06\n",
       "count  972.000000  961.000000  963.000000\n",
       "mean     2.541152    0.533717    0.540244\n",
       "std      1.703983    0.742583    0.936276\n",
       "min      0.000000   -1.715600   -3.107300\n",
       "25%      1.000000    0.033100   -0.072050\n",
       "50%      3.000000    0.511800    0.550600\n",
       "75%      4.000000    1.040300    1.151550\n",
       "max      5.000000    3.034800    3.898900"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259eb219-6e00-4ac1-b400-417e036f7146",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Introduction</h4>\n",
    "\n",
    "Briefly describe the dataset you’re given and define the goal of the project and how you approach it.\n",
    "For example, you can present a basic introduction of your data (shape and proposed data types)\n",
    "and your goal is to use these features to predict the label of the response variable.\n",
    "Then you propose a few models that are suitable for this project which will be introduced in the modeling section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4811a58d-2d2b-43db-92e3-3d05c6a24ea3",
   "metadata": {},
   "source": [
    "# Part 1: Data Cleaning\n",
    "\n",
    "As always, we should start with data cleaning.\n",
    "Take what you learned from HO3 to clean up this messy data to a point where it is ready for machine learning algorithms.\n",
    "\n",
    "Some things you may want to do:\n",
    " - Deal with missing/empty values.\n",
    " - Fix numeric columns so that they actually contain numbers.\n",
    " - Remove inconsistencies from columns.\n",
    " - Assign a data type to each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431c9f31-9286-40a6-8816-d6dfd643ab04",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Task 1.A</h4>\n",
    "\n",
    "Complete the following function that takes in a DataFrame and outputs a clean version of the DataFrame.\n",
    "You can assume that the frame has all the same structure as your unique dataset.\n",
    "You can return the same or a new data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f8eb6-71ec-4036-80e9-39cd51d67166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>col_00</th>\n",
       "      <th>col_01</th>\n",
       "      <th>col_02</th>\n",
       "      <th>col_03</th>\n",
       "      <th>col_04</th>\n",
       "      <th>col_05</th>\n",
       "      <th>col_06</th>\n",
       "      <th>col_07</th>\n",
       "      <th>col_08</th>\n",
       "      <th>col_09</th>\n",
       "      <th>col_10</th>\n",
       "      <th>col_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1847 Kg</td>\n",
       "      <td>0.2017</td>\n",
       "      <td>Running</td>\n",
       "      <td>Stockton</td>\n",
       "      <td>0.0827</td>\n",
       "      <td>1225</td>\n",
       "      <td>1.6913</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>1315 M</td>\n",
       "      <td>Santa Clarita</td>\n",
       "      <td>0.2084</td>\n",
       "      <td>1.6003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1672 Kg</td>\n",
       "      <td>0.7091</td>\n",
       "      <td>Ice Hockey</td>\n",
       "      <td>San Bernardino</td>\n",
       "      <td>1.9133</td>\n",
       "      <td>1521</td>\n",
       "      <td>1.1220</td>\n",
       "      <td>Soccer</td>\n",
       "      <td>544 M</td>\n",
       "      <td>Modesto, Moreno Valley</td>\n",
       "      <td>0.3429</td>\n",
       "      <td>0.9163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1691 Kg</td>\n",
       "      <td>0.883</td>\n",
       "      <td>Running</td>\n",
       "      <td>Stockton</td>\n",
       "      <td>0.8197</td>\n",
       "      <td>1360</td>\n",
       "      <td>-0.6893</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>1091 M</td>\n",
       "      <td>Long Beach</td>\n",
       "      <td>0.3473</td>\n",
       "      <td>-0.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-1287 Kg</td>\n",
       "      <td>0.2343</td>\n",
       "      <td>Volleyball</td>\n",
       "      <td>Irvine</td>\n",
       "      <td>0.4747</td>\n",
       "      <td>105</td>\n",
       "      <td>1.8982</td>\n",
       "      <td>Motor Sports</td>\n",
       "      <td>2086 M</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>0.1239</td>\n",
       "      <td>1.1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>205 Kg</td>\n",
       "      <td>-0.0906</td>\n",
       "      <td>Volleyball</td>\n",
       "      <td>Irvine</td>\n",
       "      <td>0.2668</td>\n",
       "      <td>1689</td>\n",
       "      <td>2.5584</td>\n",
       "      <td>Boxing</td>\n",
       "      <td>1377 M</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>0.4622</td>\n",
       "      <td>-0.0865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>4</td>\n",
       "      <td>564 Kg</td>\n",
       "      <td>1.6253</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>Long Beach, San Bernardino</td>\n",
       "      <td>-0.5722</td>\n",
       "      <td>701</td>\n",
       "      <td>1.2392</td>\n",
       "      <td>Soccer</td>\n",
       "      <td>174 M</td>\n",
       "      <td>Santa Clarita</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>-0.7681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>4</td>\n",
       "      <td>1266 Kg</td>\n",
       "      <td>1.28</td>\n",
       "      <td>Ice Hockey</td>\n",
       "      <td>Long Beach, San Francisco</td>\n",
       "      <td>1.1948</td>\n",
       "      <td>934</td>\n",
       "      <td>1.6146</td>\n",
       "      <td>Soccer</td>\n",
       "      <td>1035 M</td>\n",
       "      <td>Stockton</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>0.7681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>1</td>\n",
       "      <td>-638 Kg</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>Track &amp; Field</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-0.9981</td>\n",
       "      <td>-137</td>\n",
       "      <td>-0.2476</td>\n",
       "      <td>Track &amp; Field</td>\n",
       "      <td>-42 M</td>\n",
       "      <td>Moreno Valley, Modesto</td>\n",
       "      <td>0.1683</td>\n",
       "      <td>-0.3588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>1</td>\n",
       "      <td>-888 Kg</td>\n",
       "      <td>-0.6634</td>\n",
       "      <td>Motor Sports</td>\n",
       "      <td>Moreno Valley, Riverside, Santa Ana, Modesto</td>\n",
       "      <td>-0.1822</td>\n",
       "      <td>-319</td>\n",
       "      <td>-0.5103</td>\n",
       "      <td>Golf</td>\n",
       "      <td>1050 M</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>-0.2673</td>\n",
       "      <td>0.1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>4</td>\n",
       "      <td>1536 Kg</td>\n",
       "      <td>-0.7586</td>\n",
       "      <td>Ice Hockey</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>0.6724</td>\n",
       "      <td>1264</td>\n",
       "      <td>-0.5140</td>\n",
       "      <td>Soccer</td>\n",
       "      <td>1847 M</td>\n",
       "      <td>Fremont, Los Angeles, San Diego</td>\n",
       "      <td>1.427</td>\n",
       "      <td>1.0731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>972 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label    col_00   col_01         col_02  \\\n",
       "0        5   1847 Kg   0.2017        Running   \n",
       "1        4   1672 Kg   0.7091     Ice Hockey   \n",
       "2        5   1691 Kg    0.883        Running   \n",
       "3        2  -1287 Kg   0.2343     Volleyball   \n",
       "4        2    205 Kg  -0.0906     Volleyball   \n",
       "..     ...       ...      ...            ...   \n",
       "967      4    564 Kg   1.6253     Basketball   \n",
       "968      4   1266 Kg     1.28     Ice Hockey   \n",
       "969      1   -638 Kg   0.0518  Track & Field   \n",
       "970      1   -888 Kg  -0.6634   Motor Sports   \n",
       "971      4   1536 Kg  -0.7586     Ice Hockey   \n",
       "\n",
       "                                           col_03  col_04 col_05  col_06  \\\n",
       "0                                        Stockton  0.0827   1225  1.6913   \n",
       "1                                  San Bernardino  1.9133   1521  1.1220   \n",
       "2                                        Stockton  0.8197   1360 -0.6893   \n",
       "3                                          Irvine  0.4747    105  1.8982   \n",
       "4                                          Irvine  0.2668   1689  2.5584   \n",
       "..                                            ...     ...    ...     ...   \n",
       "967                    Long Beach, San Bernardino -0.5722    701  1.2392   \n",
       "968                     Long Beach, San Francisco  1.1948    934  1.6146   \n",
       "969                                        Fresno -0.9981   -137 -0.2476   \n",
       "970  Moreno Valley, Riverside, Santa Ana, Modesto -0.1822   -319 -0.5103   \n",
       "971                                 San Francisco  0.6724   1264 -0.5140   \n",
       "\n",
       "            col_07  col_08                           col_09   col_10   col_11  \n",
       "0       Basketball  1315 M                    Santa Clarita   0.2084   1.6003  \n",
       "1           Soccer   544 M           Modesto, Moreno Valley   0.3429   0.9163  \n",
       "2       Basketball  1091 M                       Long Beach   0.3473   -0.213  \n",
       "3     Motor Sports  2086 M                          Oakland   0.1239   1.1263  \n",
       "4           Boxing  1377 M                    San Francisco   0.4622  -0.0865  \n",
       "..             ...     ...                              ...      ...      ...  \n",
       "967         Soccer   174 M                    Santa Clarita   -0.577  -0.7681  \n",
       "968         Soccer  1035 M                         Stockton   0.1792   0.7681  \n",
       "969  Track & Field   -42 M           Moreno Valley, Modesto   0.1683  -0.3588  \n",
       "970           Golf  1050 M                         San Jose  -0.2673   0.1491  \n",
       "971         Soccer  1847 M  Fremont, Los Angeles, San Diego    1.427   1.0731  \n",
       "\n",
       "[972 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(frame):\n",
    "    # Removing rows with empty label column\n",
    "    if 'label' in frame.columns:\n",
    "        frame = frame.dropna(subset=['label'])\n",
    "    \n",
    "    # Making all empty values match in name\n",
    "    frame.replace(['N/A', '?', 'NULL', 'n/a', 'None'], pandas.NA, inplace=True)\n",
    "    \n",
    "    # Cleaning string columns\n",
    "    for i in frame.columns:\n",
    "        if frame[i].dtype == object:\n",
    "            frame[i] = frame[i].dropna().astype(str).str.strip().str.title()\n",
    "\n",
    "    # Converting numeric strings to numeric types\n",
    "    for i in frame.columns:\n",
    "        if frame[i].dtype == object:\n",
    "            try:\n",
    "                if frame[i].str.contains(r'\\d').any():\n",
    "                    frame[i] = frame[i].apply(\n",
    "                        lambda x: float(''.join(c for c in x if c.isdigit() or c == '.'))\n",
    "                        if any(c.isdigit() for c in x) else x\n",
    "                    )\n",
    "            except Exception:\n",
    "                pass\n",
    "    \n",
    "    # Assigning data types EXPLICITLY\n",
    "    for i in frame.columns:\n",
    "        if frame[i].dtype == object:\n",
    "            frame[i] = frame[i].astype('object')\n",
    "        elif frame[i].dtype == float:\n",
    "            if frame[i].dropna().mod(1).eq(0).all():\n",
    "                frame[i] = frame[i].astype('int64')\n",
    "            else:\n",
    "                frame[i] = frame[i].astype('float64')\n",
    "        elif frame[i].dtype == int:\n",
    "            frame[i] = frame[i].astype('int64')\n",
    "            \n",
    "    frame = frame.reset_index(drop=True)\n",
    "    return frame\n",
    "\n",
    "unique_data = clean_data(unique_data)\n",
    "unique_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c55d30a-550d-46f3-ad3b-c0e49a1b8a10",
   "metadata": {},
   "source": [
    "Now we should also be able to view all the numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f886c77c-0dad-47ae-ab2b-8661ec63f98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 972 entries, 0 to 971\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   label   972 non-null    int64  \n",
      " 1   col_00  963 non-null    object \n",
      " 2   col_01  967 non-null    object \n",
      " 3   col_02  958 non-null    object \n",
      " 4   col_03  966 non-null    object \n",
      " 5   col_04  961 non-null    float64\n",
      " 6   col_05  962 non-null    object \n",
      " 7   col_06  963 non-null    float64\n",
      " 8   col_07  964 non-null    object \n",
      " 9   col_08  965 non-null    object \n",
      " 10  col_09  961 non-null    object \n",
      " 11  col_10  964 non-null    object \n",
      " 12  col_11  960 non-null    object \n",
      "dtypes: float64(2), int64(1), object(10)\n",
      "memory usage: 98.8+ KB\n"
     ]
    }
   ],
   "source": [
    "unique_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bff37a-7241-4a4a-bc2d-8a30a54826f4",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Data Cleaning</h4>\n",
    "\n",
    "Describe the steps you took for data cleaning.\n",
    "Why did you do this?\n",
    "Did you have to make some choices along the way? If so, describe them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430a58e3-0ac0-4629-bc72-4a7ba71cf68e",
   "metadata": {},
   "source": [
    "# Part 2: Data Visualization\n",
    "\n",
    "Once you have cleaned up the data, it is time to explore it and find interesting things.\n",
    "Part of this exploration, will be visualizing the data in a way that makes it easier for yourself and others to understand.\n",
    "Use what you have learned in HO1 and HO2 to create some visualizations for your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c220e6d0-202a-4f9e-b5de-0167025ff2ad",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Data Visualization</h4>\n",
    "\n",
    "Create at least two different visualizations that help describe what you see in your dataset.\n",
    "Include these visualizations in your report along with descriptions of\n",
    "how you created the visualization,\n",
    "what data preparation you had to do for the visualization (aside from the data cleaning in the previous part),\n",
    "and what the visualization tells us about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1f3fb1-16c8-4079-9bdf-b8a8db02370a",
   "metadata": {},
   "source": [
    "# Part 3: Modeling\n",
    "\n",
    "Now that you have a good grasp of your clean data,\n",
    "it is time to do some machine learning!\n",
    "(Technically all our previous steps were also machine learning,\n",
    "but now we get to use classifiers!)\n",
    "\n",
    "Use the skills you developed to select **three** classifiers and implement them on your data.\n",
    "For example, you can narrow down your choices to three classifiers which may include:\n",
    "- Logistic regression\n",
    "- K-nearest neighbors\n",
    "- Decision tree\n",
    "- Or others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924e896-2c73-4c83-89b4-54c6a8423e69",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Task 3.A</h4>\n",
    "\n",
    "Complete the following function that takes in no parameters,\n",
    "and returns a list with **three** untrained classifiers you are going to explore in this assignment.\n",
    "This method may set parameters/options for the classifiers, but should not do any training/fitting.\n",
    "\n",
    "For example, if you wanted to use logistic regression,\n",
    "then **one** of your list items may be:\n",
    "```\n",
    "sklearn.linear_model.LogisticRegression()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce3b3a5-91a3-4c7a-85f1-84b266a5a781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(), DecisionTreeClassifier(), SVC()]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_classifiers():\n",
    "    logistic_regression = sklearn.linear_model.LogisticRegression()\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    svc = sklearn.svm.SVC()\n",
    "    return [logistic_regression, decision_tree, svc]\n",
    "\n",
    "my_classifiers = create_classifiers()\n",
    "my_classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c115a2-9b07-438a-bd5f-682c22078ca2",
   "metadata": {},
   "source": [
    "Now that we have some classifiers, we can see how they perform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7795bb4a-4545-47fc-9c77-4861a4820333",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Task 3.B</h4>\n",
    "\n",
    "Complete the following function that takes in an untrained classifier, a DataFrame, and a number of folds.\n",
    "This function should run k-fold cross validation with the classifier and the data,\n",
    "and return a list with the accuracy of each run of cross validation.\n",
    "You can assume that the frame has the column `label` and the rest of the columns can be considered clean numeric features.\n",
    "\n",
    "Note that you may have to break your frame into features and labels to do this.\n",
    "Do not change the passed-in frame (make copies instead).\n",
    "\n",
    "If you are getting any `ConvergenceWarning`s you may either ignore them,\n",
    "or try and address them\n",
    "(they will not affect your autograder score, but may be something to discuss in the written portion of this assignment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770c5ea-18fe-41f3-ad5b-e72f463be876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/hanarazia/cse40_venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/hanarazia/cse40_venv/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/hanarazia/cse40_venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n  File \"/Users/hanarazia/cse40_venv/lib/python3.9/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/hanarazia/cse40_venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n    X = check_array(\n  File \"/Users/hanarazia/cse40_venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n    _assert_all_finite(\n  File \"/Users/hanarazia/cse40_venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/hanarazia/cse40_venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m my_classifiers_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m classifier \u001b[38;5;129;01min\u001b[39;00m my_classifiers:\n\u001b[0;32m---> 35\u001b[0m     accuracy_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_fold_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     my_classifiers_scores\u001b[38;5;241m.\u001b[39mappend(accuracy_scores)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassifier: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(classifier)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, accuracy_scores))\n",
      "Cell \u001b[0;32mIn[15], line 28\u001b[0m, in \u001b[0;36mcross_fold_validation\u001b[0;34m(classifier, frame, folds)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39mhstack([X_numeric, X_categorical])\n\u001b[1;32m     26\u001b[0m X_preprocessed \u001b[38;5;241m=\u001b[39m preprocess_data(X)\n\u001b[0;32m---> 28\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_selection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_preprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/cse40_venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/cse40_venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/cse40_venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/cse40_venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:443\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m    423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    425\u001b[0m         clone(estimator),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    441\u001b[0m )\n\u001b[0;32m--> 443\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[0;32m~/cse40_venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/hanarazia/cse40_venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/hanarazia/cse40_venv/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/hanarazia/cse40_venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n  File \"/Users/hanarazia/cse40_venv/lib/python3.9/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/hanarazia/cse40_venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n    X = check_array(\n  File \"/Users/hanarazia/cse40_venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n    _assert_all_finite(\n  File \"/Users/hanarazia/cse40_venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/hanarazia/cse40_venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "def cross_fold_validation(classifier, frame, folds):\n",
    "    X = frame.iloc[:, 1:]\n",
    "    y = frame.iloc[:, 0]\n",
    "\n",
    "    # Identifying each column\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "    numeric_cols = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "    # Helper func for data preprocessing\n",
    "    def preprocess_data(X):\n",
    "        X[categorical_cols] = X[categorical_cols].fillna('Missing')\n",
    "    \n",
    "        # One hot encoding for categorical data\n",
    "        one_hot_encoder = sklearn.preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "        X_categorical = one_hot_encoder.fit_transform(X[categorical_cols]).toarray()\n",
    "    \n",
    "        X_numeric = X[numeric_cols].to_numpy()\n",
    "    \n",
    "        # Scaling numeric data\n",
    "        scaler = sklearn.preprocessing.StandardScaler()\n",
    "        X_numeric = scaler.fit_transform(X_numeric)\n",
    "    \n",
    "        # Combining data\n",
    "        return numpy.hstack([X_numeric, X_categorical])\n",
    "\n",
    "    X_preprocessed = preprocess_data(X)\n",
    "\n",
    "    scores = sklearn.model_selection.cross_val_score(\n",
    "        classifier, X_preprocessed, y, cv=folds, scoring='accuracy'\n",
    "    )\n",
    "    return scores.tolist()\n",
    "\n",
    "my_classifiers_scores = []\n",
    "for classifier in my_classifiers:\n",
    "    accuracy_scores = cross_fold_validation(classifier, unique_data, 5)\n",
    "    my_classifiers_scores.append(accuracy_scores)\n",
    "    print(\"Classifier: %s, Accuracy: %s.\" % (type(classifier).__name__, accuracy_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c8552-9d78-4393-a9e8-f1e583e0e93e",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Task 3.C</h4>\n",
    "\n",
    "Complete the following function that takes in two equally-sized lists of numbers and a p-value.\n",
    "This function should compute whether there is a statistical significance between\n",
    "these two lists of numbers using a [Student's t-test](https://en.wikipedia.org/wiki/Student%27s_t-test)\n",
    "at the given p-value.\n",
    "Return `True` if there is a statistical significance, and `False` otherwise.\n",
    "Hint: If you wish, you may use the `ttest_ind()` [method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html) provided in the scipy package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c9500-b91a-400a-8f1a-4f1e971fca26",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(my_classifiers)):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(my_classifiers)):\n\u001b[0;32m----> 7\u001b[0m         significant \u001b[38;5;241m=\u001b[39m significance_test(\u001b[43mmy_classifiers_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, my_classifiers_scores[j], \u001b[38;5;241m0.10\u001b[39m)\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(my_classifiers[i])\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m      9\u001b[0m                                 \u001b[38;5;28mtype\u001b[39m(my_classifiers[j])\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, significant))\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def significance_test(a_values, b_values, p_value):\n",
    "    t_stat, p_val = ttest_ind(a_values, b_values, equal_var=False)\n",
    "    return p_val < p_value\n",
    "    \n",
    "for i in range(len(my_classifiers)):\n",
    "    for j in range(i + 1, len(my_classifiers)):\n",
    "        significant = significance_test(my_classifiers_scores[i], my_classifiers_scores[j], 0.10)\n",
    "        print(\"%s vs %s: %s\" % (type(my_classifiers[i]).__name__,\n",
    "                                type(my_classifiers[j]).__name__, significant))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea725c-f53a-48a6-a939-93c88a366905",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Modeling</h4>\n",
    "\n",
    "Describe the classifiers you have chosen.\n",
    "Be sure to include all details about any parameter settings used for the algorithms.\n",
    "\n",
    "Compare the performance of your models using k-fold validation.\n",
    "You may look at accuracy, F1 or other measures.\n",
    "\n",
    "Then, briefly summarize your results.\n",
    "Are your results statistically significant?\n",
    "Is there a clear winner?\n",
    "What do the standard deviations look like, and what do they tell us about the different models?\n",
    "Include a table like Table 1.\n",
    "\n",
    "<center>Table 1: Every table needs a caption.</center>\n",
    "\n",
    "| Model | Mean Accuracy | Standard Deviation of Accuracy |\n",
    "|-------|---------------|--------------------------------|\n",
    "| Logistic Regression | 0.724 | 0.004\n",
    "| K-Nearest Neighbor | 0.750 | 0.003\n",
    "| Decision Tree | 0.655 | 0.011"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4127f125-5ddf-4bc6-a6b6-4679cb0158d1",
   "metadata": {},
   "source": [
    "# Part 4: Analysis\n",
    "\n",
    "Now, take some time to go over your results for each classifier and try to make sense of them.\n",
    " - Why do some classifiers work better than others?\n",
    " - Would another evaluation metric work better than vanilla accuracy?\n",
    " - Is there still a problem in the data that should fixed in data cleaning?\n",
    " - Does the statistical significance between the different classifiers make sense?\n",
    " - Are there parameters for the classifier that I can tweak to get better performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f6ef88-5094-4692-acad-22eb38d3713e",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Analysis</h4>\n",
    "\n",
    "Discuss your observations, the relationship you found, and how you applied concepts from the class to this project.\n",
    "For example, you may find that some feature has the most impact in predicting your response variable or removing a feature improves the model accuracy.\n",
    "Or you may observe that your training accuracy is much higher than your test accuracy and you may want to explain what issues may arise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26983b3b-cbb1-4f7f-a15d-95f0a654b5ea",
   "metadata": {},
   "source": [
    "# Part 5: Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ecfa57-af63-472f-9041-b08bb5506fb9",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Conclusion</h4>\n",
    "\n",
    "Briefly summarize the important results and conclusions presented in the project.\n",
    "What are the important points illustrated by your work?\n",
    "Are there any areas for further investigation or improvement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d7f964-b4e6-4b84-a0fd-9d815f06980e",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: References</h4>\n",
    "\n",
    "Include a standard bibliography with citations referring to techniques or published papers you used throughout your report (if you used any).\n",
    "\n",
    "For example:\n",
    "```\n",
    "[1] Derpanopoulos, G. (n.d.). Bayesian Model Checking & Comparison.\n",
    "https://georgederpa.github.io/teaching/modelChecking.html.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f6601-a2e8-4bd8-aa58-b1b4b9310454",
   "metadata": {},
   "source": [
    "# Part XC: Extra Credit\n",
    "\n",
    "So far you have used a synthetic dataset that was created just for you.\n",
    "But, data science is always more interesting when you are dealing with actual data from the real world.\n",
    "Therefore, you will have an opportunity for extra credit on this assignment using real-world data.\n",
    "\n",
    "For extra credit, repeat the **written tasks** of Parts 0 through 4 with an additional dataset that you find yourself.\n",
    "For the written portion of the extra credit for Part 0, include information about where you got the data and what the data represents.\n",
    "You may choose any dataset that represents real data (i.e., is **not** synthetic or generated)\n",
    "and is **not** [pre-packaged in scikit-learn](https://scikit-learn.org/stable/datasets.html).\n",
    "\n",
    "Below are some of the many places you can start looking for datasets:\n",
    " - [Kaggle](https://www.kaggle.com/datasets) -- Kaggle is a website focused around machine learning competitions,\n",
    "       where people compete to see who can get the best results on a dataset.\n",
    "       It is very popular in the machine learning community and has thousands of datasets with descriptions.\n",
    "       Make sure to read the dataset's description, as Kaggle also has synthetic datasets.\n",
    " - [data.gov](https://data.gov/) -- A portal for data from the US government.\n",
    "        The US government has a lot of data, and much of it has to be available to the public by law.\n",
    "        This portal contains some of the more organized data from several different government agencies.\n",
    "        In general, the government has A LOT of interesting data.\n",
    "        It may not always be clean (remember the CIA factbook), but it is interesting and available.\n",
    "        All data here should be real-world, but make sure to read the description to verify.\n",
    " - [UCI's Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets.php) -- UC Irvine has their own data repository with a few hundred datasets on many different topics.\n",
    "        Make sure to read the dataset's description, as UCI also has synthetic datasets.\n",
    " - [WHO's Global Health Observatory](https://apps.who.int/gho/data/node.home) -- The World Health Organization keeps track of many different health-related statistics for most of the countries in the world.\n",
    "        All data here should be real-world, but make sure to read the description to verify.\n",
    " - [Google's Dataset Search](https://datasetsearch.research.google.com/) -- Google indexes many datasets that can be searched here.\n",
    "\n",
    "You can even create a dataset from scratch if you find some data you like that is not already organized into a specific dataset.\n",
    "The only real distinction between \"data\" and a \"dataset\" is that a dataset is organized and finite (has a fixed size).\n",
    "\n",
    "Create a new section in your written report for this extra credit and include all the written tasks for the extra credit there.\n",
    "Each written task/section that you complete for your new dataset is eligible for extra credit (so you can still receive some extra credit even if you do not complete all parts).\n",
    "There is no need to submit any code for the extra credit.\n",
    "If you created a new dataset, include the dataset or links to it with your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
